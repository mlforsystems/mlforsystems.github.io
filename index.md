---
title: Announcement
workshop_name: neurips2024
site_description: Workshop on ML for Systems at NeurIPS 2024, December 15, Vancouver Convention Center
mini_site_description: Workshop on ML for Systems at NeurIPS '24, Dec 15
site_title: ML For Systems
---
<div class="speaker_section">
  <div class="inner clearfix">
    <section class="main-content">
      <h2 id="speakers">Speakers</h2>
	    <div class="speaker-bio">
			<div class="img-holder" style="background-image: url(/assets/images/speakers/jeff_dean.jpg)"></div>
			<div>
				<h3 class="keynote-speaker">Jeff Dean</h3>
                <h5 class="keynote-speaker">Keynote Speaker</h5>
                <h3>Exciting Directions in Machine Learning for Computer Systems</h3>
				<p>
                    Jeff Dean joined Google in mid-1999, and is currently Google's Chief Scientist, focusing on AI advances for Google
                    DeepMind and Google Research. His areas of focus include machine learning and AI and applications of AI to
                    problems that help billions of people in societally beneficial ways. Jeff co-founded Google Brain and is a co-designer
                    and implementer of Tensorflow, MapReduce, BigTable and Spanner. He has been involved in several ML for Systems
                    projects, including Learned Index Structures and ML for chip floorplanning.
				</p>
			</div>
        </div>
        <div class="speaker-bio">
			<div class="img-holder" style="background-image: url(/assets/images/speakers/richard_ho.jpg)"></div>
			<div>
				<h3 class="keynote-speaker">Richard Ho</h3>
                <h5 class="keynote-speaker">Hardware</h5>
                <h3>Navigating Scaling and Efficiency Challenges of ML Systems</h3>
				<p>Richard is Head of Hardware at OpenAI working to co-optimize ML models and the massive compute hardware they run on. Richard was one of the early engineers working on Google TPUs and helped lead the team through TPUv5. Before Google, Richard was part of the D. E. Shaw Research team that built the Anton 1 and Anton 2 molecular dynamics simulation supercomputers, both of which won the Gordon Bell Prize. Richard started his career as co-founder and Chief Architect of 0-In Design Automation, a pioneer in formal verification tools for chip design which was acquired by Mentor Graphics/Siemens. Richard has a Ph.D. in Computer Science from Stanford University and M.Eng, B.Sc. from University of Manchester, UK.
				</p>
			</div>
        </div>
        <div class="speaker-bio">
			<div class="img-holder" style="background-image: url(/assets/images/speakers/kraska.jpg)"></div>
			<div>
				<h3 class="keynote-speaker">Tim Kraska</h3>
                <h5 class="keynote-speaker">Retrospective</h5>
                <h3>TBD</h3>
				<p>Tim Kraska is an associate professor of electrical engineering and computer science at MIT and director of applied science for Amazon Web Services. His work focuses on Learned Systems: ML for Systems, and Systems for ML.
				</p>
			</div>
        </div>
        <div class="speaker-bio">
				<div class="img-holder" style="background-image: url(/assets/images/speakers/jacques.jpg)"></div>
				<div>
					<h3 class="keynote-speaker">Natasha Jacques</h3>
          <h5 class="keynote-speaker">Special Topic: MARL</h5>
                    <h3>TBD</h3>
					<p>Natasha Jacques is an Assistant Professor at the University of Washington Paul G. Allen School of Computer Science & Engineering, where she leads the <a href="https://socialrl.cs.washington.edu/">Social RL Lab</a>. She is also a Senior Research Scientist at Google DeepMind. Her work develops algorithms for Social Reinforcement Learning, which combine insights from social learning and multi-agent training to improve AI agents’ learning, generalization, coordination, and human-AI interaction. She is a pioneer in using RL for finetuning language models and learning from human feedback.
					</p>
				</div>
        </div>
            <div class="speaker-bio">
				<div class="img-holder" style="background-image: url(/assets/images/speakers/ahmed.jpeg)"></div>
				<div>
					<h3 class="keynote-speaker">Ahmed El-Kishky</h3>
          <h5 class="keynote-speaker">Special Topic: CodeGen</h5>
                    <h3>OpenAI o1 Competing in International Olympiad of Informatics</h3>
					<p>Ahmed El-Kishky is a Research Lead at OpenAI, where he focuses on advancing language models and improving AI reasoning through reinforcement learning. He was instrumental in developing OpenAI o1, a model built for complex problem-solving, and led the creation of OpenAI o1-IOI, which competed in prestigious programming competitions such as the International Olympiad in Informatics. Ahmed earned his Ph.D. in Computer Science from the University of Illinois at Urbana-Champaign, where his research centered on scalable machine learning algorithms and natural language processing.
					</p>
				</div>
        </div>
    </section>
</div>
</div>
<div class="inner clearfix">
	<section class="main-content overview_section">
		<h2>What To Expect</h2>
        <p>The ML for Systems workshop presents cutting-edge work on ML in computer systems and aims to develop a unified methodology for the field.
        </p>
        <p>Machine Learning (ML) for Systems describes the application of machine learning techniques to problems related to computer systems. By leveraging supervised learning and reinforcement learning (RL) approaches, machine learning can replace longstanding heuristics that currently drive many of these systems. This includes a wide range of topics, including multi-objective tasks such as designing new data structures <sup><a href="https://arxiv.org/abs/1706.04972">1</a></sup>, integrated circuits <sup><a href="https://openreview.net/forum?id=Hkc-TeZ0W">2</a>, <a href="https://arxiv.org/abs/1712.01208">3</a></sup>, or design verification <sup><a href="https://dvcon-proceedings.org/wp-content/uploads/Adaptive-Test-Generation-for-Fast-Functional-Coverage-Closure.pdf">20</a>, <a href="https://dvcon-proceedings.org/wp-content/uploads/Test-Parameter-Tuning-with-Blackbox-Optimization-A-Simple-Yet-Effective-Way-to-Improve-Coverage-1.pdf">21</a></sup>, as well as implementing control algorithms for applications such as compilers <sup><a href="https://arxiv.org/abs/1805.03441">12</a>, <a href="https://arxiv.org/abs/1805.08166">13</a>, <a href="https://arxiv.org/abs/2011.14486">19</a></sup>, databases <sup><a href="https://arxiv.org/abs/1711.11165">8</a></sup>, memory management <sup><a href="https://arxiv.org/abs/1803.02329">9</a>, <a href="https://research.google/pubs/pub49008/">10</a></sup>, or ML frameworks <sup><a href="https://arxiv.org/abs/1906.08879">11</a></sup>. While the systems community increasingly recognizes the importance of ML in solving a variety of different systems problems <sup><a href="https://www.sigarch.org/5-guidelines-for-research-in-ml-for-systems/">23</a></sup>, ML for Systems remains an emerging area without widely established best practices, methods and strategies for the application of state-of-the-art machine learning techniques <sup><a href="https://ieeexplore.ieee.org/document/9153088">22</a></sup>. The goal of this workshop is to provide an interdisciplinary venue for ML and Systems experts to push this boundary and start new directions within the ML for Systems area.
        </p>
        <h3>Workshop Direction</h3>
        <p>
        In previous 6 editions, we showcased specific approaches and frameworks to solve problems, bringing together researchers and practitioners at NeurIPS from both the ML and systems communities. While breaking new grounds, we encouraged collaborations and development in a broad range of ML for Systems works, many later published in top-tier conferences <sup><a href="https://arxiv.org/abs/1906.08879">11</a>, <a href="https://arxiv.org/abs/1805.08166">13</a>, <a href="https://arxiv.org/abs/1810.01963">14</a>, <a href="https://arxiv.org/abs/1811.01704">15</a>, <a href="https://arxiv.org/abs/1808.07412">16</a>, <a href="https://arxiv.org/abs/2104.04955">17</a>, <a href="https://dl.acm.org/doi/10.1145/3439706.3447045">18</a></sup>. This year, we plan to continue this path while encouraging work in key emerging areas such as Large Language Model (LLM) training and serving, and unifying benchmarks on key problems such as scheduling and compiling through a competition.
        </p>
        <p>Recently, the rise of Large Language Models (LLMs) has presented new opportunities and challenges within the domain of computer systems. Our community is well-positioned to produce science and stimulate discussion for adapting to the new paradigm, especially how LLMs can be used to solve systems problems, and using ML to address systems issues that emerge from LLM training and serving. Additionally, as the field matures, we emphasize on keeping the research open, and the science reproducible. To that end, we are supplementing our main program with a competition track to crystallize the field’s progress.
        </p>
        <h3>Workshop Goals </h3>
        <p>NeurIPS provides a unique opportunity to bring together systems researchers and researchers from other sub-areas of ML who had not previously considered applying their techniques in a computer systems context. We see the goal of our workshop as solving the following two objectives:
        <ul>
            <li>Opening up connections between research areas that were not previously considered, connecting the ML and Systems communities, growing the scope of ML for Systems work and unlocking new research opportunities.</li>
            <li>Developing best practices, methodologies and benchmarks for the ML for Systems field.</li>
        </ul>
        </p>
        <p>To build commonalities on the topic of LLMs interacting with computational systems, we specifically include seminal talks on emerging trends on training and serving LLMs from seasoned researchers and practitioners as a part of our invited speakers. Our call for papers also includes topics at the intersection of Systems and LLMs.
        </p>
        <p>Our program include contributed speakers and poster sessions from selected works. Our <a href="/schedule.html">schedule</a> is available. We invited researchers to submit relevant papers through our <a href="/call_for_papers.html">call for papers</a>.</p>
	</section>
</div>
<div class="organizers-section">
	<div class="inner clearfix">
		<section class="main-content">
			<h2>Organizing Committee</h2>
			<ul>
				<li><b>Mimee Xu</b>, NYU, <a href="https://twitter.com/MimeeXu">@MimeeXu</a></li>
                <li><b>Dan Zhang</b>, Google DeepMind, <a href="https://www.linkedin.com/in/danzhang3">LinkedIn</a></li>
                <li><b>Phitchaya Mangpo Phothilimthana</b>, Google DeepMind, <a href="https://www.linkedin.com/in/phitchaya-mangpo-phothilimthana">LinkedIn</a></li>
                <li><b>Divya Mahajan</b>, Georgia Tech, <a href="https://twitter.com/divyamahajn">@DivyaMahajn</a></li>
                <li><b>Haoran Qiu</b>, Microsoft Azure Research, <a href="https://www.linkedin.com/in/jamesqhr/">LinkedIn</a></li>
                <li><b>Patrick Musau</b>, Google. <a href="https://www.linkedin.com/in/musaup/">LinkedIn</a></li>
			</ul>
            <h2>Steering Committee</h2>
			<ul>
                <li><b>Martin Maas</b>, Google DeepMind, <a href="https://twitter.com/martin_maas">@martin_maas</a></li>
                <li><b>Jonathan Raiman</b>, NVIDIA, <a href="https://twitter.com/jonathanrraiman">@jonathanrraiman</a></li>
                <li><b>Anna Goldie</b>, Anthropic, <a href="https://twitter.com/annadgoldie">@annadgoldie</a></li>
                <li><b>Azalia Mirhoseini</b>, Anthropic, <a href="https://twitter.com/Azaliamirh">@Azaliamirh</a></li>
				<li><b>Milad Hashemi</b>, Google, <a href="https://twitter.com/miladhash">@miladhash</a></li>
				<li><b>Kevin Swersky</b>, Google, <a href="https://twitter.com/kswersk">@kswersk</a></li>
			</ul>
            <h2>Contact Us</h2>
            <p>
                Contact us at <a href="mailto:mlforsystems@googlegroups.com">mlforsystems@googlegroups.com</a>.
            </p>
		</section>
</div>
