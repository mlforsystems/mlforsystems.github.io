---
title: Schedule
workshop_name: neurips2023
site_description: Workshop on ML for Systems at NeurIPS 2023
mini_site_description: Workshop on ML for Systems at NeurIPS 2023
site_title: ML For Systems
---

<div class="speaker_section">
  <div class="inner clearfix">
    <section class="main-content">
      <h2 id="speakers">Speakers</h2>
	    <div class="speaker-bio">
				<div class="img-holder" style="background-image: url(/assets/images/speakers/chris_lattner.jpeg)"></div>
				<div>
					<h3 class="keynote-speaker">Keynote: Programming Languages Challenges in Large Scale Machine Learning</h3>
					<h4>Chris Lattner (Modular.ai)</h4>
					<p>
                        Chris is the co-founder and CEO of Modular AI. He cofounded the LLVM Compiler infrastructure, the Clang compiler, the Swift programming language, the MLIR compiler infrastructure, the CIRCT project (applying MLIR to hardware design), and have contributed to many other commercial and open source projects at Apple, Tesla, Google, and SiFive. Previously, Chris led the Engineering and Product teams at SiFive, the Google TensorFlow team, the Tesla Autopilot team, and worked for Apple managing the Developer Tools department.
					</p>
				</div>
        </div>
    	<div class="speaker-bio">
			<div class="img-holder" style="background-image: url(/assets/images/speakers/bill_dally.jpeg)"></div>
				<div>
					<h3 class="talk-speaker">Special Speaker: Adapting Large Language Models for Chip Design at NVIDIA</h3>
					<h4>William Dally (NVIDIA)</h4>
					<p>
					    Dr. William "Bill" Dally is a computer architecture pioneer with extensive experience in circuit design, high performance computing, and machine learning. In 2009, Dally joined NVIDIA as the chief scientist, where he is currently the SVP of Research. Previously, Dally led research teams at Stanford for 12 years and MIT for 11 years as a professor, and he co-founded two companies. e is a member of the National Academy of Engineering, a Fellow of the American Academy of Arts & Sciences, a Fellow of the IEEE and the ACM, and has received the ACM Eckert-Mauchly Award, the IEEE Seymour Cray Award, and the ACM Maurice Wilkes award. He has published over 250 papers, holds over 120 issued patents, and is an author of four textbooks. His work can be seen in most large parallel computers today.
					</p>
				</div>
        </div>
        <div class="speaker-bio">
                <div class="img-holder" style="background-image: url(/assets/images/speakers/atlas_wang.jpg)"></div>
				<div>
					<h3 class="talk-speaker">Leveraging Sparsity for Efficient Training, Inference, and Transfer</h3>
					<h4>Atlas Wang (The University of Texas at Austin)</h4>
					<p>Professor Zhangyang "Atlas" Wang is an associate professor at UT Austin, where he holds the Temple Foundation Endowed Faculty Fellowship #7, in the Chandra Family Department of Electrical and Computer Engineering. He is also a faculty member of UT Computer Science (GSC) and the Oden Institute CSEM program. Wang directs AI Research and Technology at Picsart part time.  Wang is a recipient of numerous awards, including NSF CAREER, IEEE AI's 10 To Watch, and Google Research Scholar awards.
					</p>
				</div>
        </div>

<div class="contact-us-section">
    <div class="inner clearfix">
        <section class="main-content">
            <h2>Contact Us</h2>
            <p>
                Contact us at <a href="mailto:mlforsystems@googlegroups.com">mlforsystems@googlegroups.com</a>.
            </p>
        </section>
    </div>
</div>
